{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from transformers.data.processors.squad import SquadV2Processor, SquadExample, squad_convert_examples_to_features\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json, torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cuad data\n",
    "\n",
    "data_path = \"../cuad-data/train_separate_questions.json\"\n",
    "\n",
    "sample_path = \"../cuad-data/cuad_sample.json\"\n",
    "\n",
    "def get_data(path):\n",
    "    with open(path,'r') as fobj:\n",
    "        data = json.loads(fobj.read())\n",
    "        data = data[\"data\"]\n",
    "    return data\n",
    "\n",
    "def whitespace_tokenize(text):\n",
    "    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def is_whitespace(c):\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "      return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting hyperparameters\n",
    "max_seq_length = 512\n",
    "doc_stride = 256\n",
    "n_best_size = 1\n",
    "max_query_length = 64\n",
    "max_answer_length = 512\n",
    "do_lower_case = False\n",
    "null_score_diff_threshold = 0.0\n",
    "batch_size = 2\n",
    "threads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(input_data, is_training=False):\n",
    "    examples = []\n",
    "    for entry in tqdm(input_data):\n",
    "        title = entry[\"title\"]\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            context_text = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                question_text = qa[\"question\"]\n",
    "                start_position_character = None\n",
    "                answer_text = None\n",
    "                answers = []\n",
    "\n",
    "                is_impossible = qa.get(\"is_impossible\", False)\n",
    "                if not is_impossible:\n",
    "                    if is_training:\n",
    "                        answer = qa[\"answers\"][0]\n",
    "                        answer_text = answer[\"text\"]\n",
    "                        start_position_character = answer[\"answer_start\"]\n",
    "                    else:\n",
    "                        answers = qa[\"answers\"]\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    context_text=context_text,\n",
    "                    answer_text=answer_text,\n",
    "                    start_position_character=start_position_character,\n",
    "                    title=title,\n",
    "                    is_impossible=is_impossible,\n",
    "                    answers=answers,\n",
    "                )\n",
    "                examples.append(example)\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_pos_mask(dataset):\n",
    "    \"\"\"\n",
    "    Returns a list, pos_mask, where pos_mask[i] indicates is True if the ith example in the dataset is positive\n",
    "    (i.e. it contains some text that should be highlighted) and False otherwise.\n",
    "    \"\"\"\n",
    "    pos_mask = []\n",
    "    for i in range(len(dataset)):\n",
    "        ex = dataset[i]\n",
    "        start_pos = ex[3]\n",
    "        end_pos = ex[4]\n",
    "        is_positive = end_pos > start_pos\n",
    "        pos_mask.append(is_positive)\n",
    "    return pos_mask\n",
    "\n",
    "\n",
    "def get_random_subset(dataset, keep_frac=1):\n",
    "    \"\"\"\n",
    "    Takes a random subset of dataset, where a keep_frac fraction is kept.\n",
    "    \"\"\"\n",
    "    keep_indices = [i for i in range(\n",
    "        len(dataset)) if np.random.random() < keep_frac]\n",
    "    subset_dataset = torch.utils.data.Subset(dataset, keep_indices)\n",
    "    return subset_dataset\n",
    "\n",
    "\n",
    "def get_balanced_dataset(dataset):\n",
    "    \"\"\"\n",
    "    returns a new dataset, where positive and negative examples are approximately balanced\n",
    "    \"\"\"\n",
    "    pos_mask = get_dataset_pos_mask(dataset)\n",
    "    neg_mask = [~mask for mask in pos_mask]\n",
    "    npos, nneg = np.sum(pos_mask), np.sum(neg_mask)\n",
    "\n",
    "    # So that in expectation there will be npos negative examples (--> balanced)\n",
    "    neg_keep_frac = npos / nneg\n",
    "    neg_keep_mask = [mask and np.random.random(\n",
    "    ) < neg_keep_frac for mask in neg_mask]\n",
    "\n",
    "    # keep all positive examples and subset of negative examples\n",
    "    keep_mask = [pos_mask[i] or neg_keep_mask[i] for i in range(len(pos_mask))]\n",
    "    keep_indices = [i for i in range(len(keep_mask)) if keep_mask[i]]\n",
    "\n",
    "    subset_dataset = torch.utils.data.Subset(dataset, keep_indices)\n",
    "    return subset_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_and_dataset(examples, is_training=False):\n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        doc_stride=doc_stride,\n",
    "        max_query_length=max_query_length,\n",
    "        is_training=is_training,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=threads,\n",
    "    )\n",
    "\n",
    "    if is_training:\n",
    "        dataset = get_balanced_dataset(dataset)\n",
    "    \n",
    "    return features, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at MariamD/distilbert-base-uncased-finetuned-legal_data were not used when initializing DistilBertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at MariamD/distilbert-base-uncased-finetuned-legal_data and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"MariamD/distilbert-base-uncased-finetuned-legal_data\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"MariamD/distilbert-base-uncased-finetuned-legal_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.14s/it]\n",
      "convert squad examples to features:   0%|          | 0/124 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sdata = get_data(sample_path)\n",
    "sexamples = create_examples(sdata, True)\n",
    "features, dataset = create_features_and_dataset(sexamples, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c874fb5ab2ac646f527aac14c742cf4e8663a966bef244effd772608e59ca5a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('cuad': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
